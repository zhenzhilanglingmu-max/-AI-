＃特徴量エンジニアリング
＃エンコーディング
＃

特徴量エンジニアリングは、やることが多い「特徴を機械学習モデルが学習しやすいように、整理すること」
・特徴量エンジニアリングのキモは、カテゴリデータのエンコーディング

中身の説明していこ、多いでほんまに

１
数値系
・標準化（standordizatino)
平均を「０」、分散を「１」に揃える、線形モデルやＳＶＭで重要

・正規化（ｎｏｒｍａｌｉｚａｔｉｎｏ）
０～１に収める、ニューラルネットとか距離ベースで有効

・対数変換
外れ値がデカすぎる時に効く（例えば、売上金額）

１０００万を「７」に変換すること
桁を圧縮すること「スケール圧縮」
LOG１０（常用対数を使うこと）

・１０⇒１　１００⇒２　１０００⇒３　１００００⇒４　１０００００００⇒７
「０」の数を数えてる

２
カテゴリ系ここが重要！

・ラベルエンコーディング
文字を数字に変えるだけ　（例　赤色⇒１）

・ワンホットエンコーディング
カテゴリごとに列を作ってフラグ

例え、（赤チーム）　（青チーム）　（緑チーム）って分類してる
　カテゴリごとに列を作って「分類」してるって感じい

それぞれの列に一人ずつ
　　赤　青　緑
赤　１　０　０　一人
青　０　１　０　一人
緑　０　０　１　一人　　　　このくらい少ないカテゴリ分けやったら使える

・ターゲットエンコーディング
カテゴリを目的変数の平均で置換　強力やけど、リークに注意

・目的変数が買った＝１　買わない＝０という二値
（０/１）分類やとして

・あるカテゴリ（例　学生　社会人　主婦）の中で
「買った」の割合（＝平均値）を計算する
職業ごとのAiphone購入データがあったとすると

職業　　　　　　購入（買った）＝１　　　　　　買わない＝０
学生　　　　　　　１
学生　　　　　　　０
学生　　　　　　　０
社会人　　　　　　１
社会人　　　　　　１
主婦　　　　　　　０
主婦　　　　　　　１

平均すると、学生（１＋０＋０）/３＝０．３３
　　　　　　社会人（１＋１）/２＝１．０
　　　　　　主婦　（０＋１）/２＝０．５

この平均が、ターゲットエンコーディング後の値

・学習データだけで平均を計算しないとダメ
・テストデータも混ざってしまったらデータリークしてしまって、正確なデータができない

・頻度（カウント）エンコーディング

・カテゴリの出現回数で置換、カテゴリ数が多いときに便利
カテゴリに分けて、そのカテゴリが出てきた回数をカウントするだけ

・学生３００回　社会人１２００回　主婦４００回

・エンベティング
カテゴリデータを低次元の数値ベクトルに変換して、意味や関係性を持たせられること

























　　　　　　　　　


















































