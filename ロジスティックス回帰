＃ロジスティックス回帰
＃回帰＃線形＃非線形
＃分類モデル＃シグモイド関数
＃ソフトマックス関数


ロジスティックス回帰、
線形モデルに、非線形変換（シグモイド関数）を加えた
確率出力型の分類モデル

途中までは、線形で出力の時に二クラスやったらシグモイド関数
三つ以上の時はソフトマックス関数を加えると
分類モデルになるってこと

例えば、どら焼きを買うか買わないかを二つに分けるとき
買う確率、買わない確率で見れる

数字で表すと　ロジスティックス回帰は、０～１の範囲で収まるように確率でだしてくれるモデル

０．５以上は買う
０．５以下では買わない

この分けるときに使うのがシグモイド関数（二クラス分類の時）

三つ以上の分類の時は、ソフトマックス関数を使う
（出力はそれぞれ、のクラスに属する確率の合計が（１）になることで比較しやすい

合計が１ということ、二クラス分類
これはまさに、確率分布と二項分布　統計学につながっているんやな
