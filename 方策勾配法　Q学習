＃方策勾配法
＃Q学習
＃機械学習
＃強化学習
＃価値関数
＃イプシロングリーディー

方策勾配法は、学んだ行動確率従って行動する学習方法

Q学習は、最大の価値が得られるように行動する学習方法


方策勾配法　方策（ポリシーに従って行動　ルールや方針のこと）policy Gradient

・学んだ行動確率に従って行動する
・基本的には、いい方向に進むように確率を更新して学習
・行動は確率的に選ばれるから、良くない行動も選ぶこともある

例えば、
学校の教育で、進路がある程度パターン化される
（高校⇒大学⇒就職みたいな感じ　確率ルールに従って進む）


Q学習（Q leaning)

・価値（Q値）を最大化する行動を選ぶ
・常にいい選択ができるように価値関数を更新
・ただし、探索のために、時々あえて違う行動も選ぶ（基本的にはイプシロングリーディーなどで）

例えば、
いい会社に入れる道を常に探し、ほぼ確実な進路を選ぶ（Q学習）、ただし、新しい可能性を試す（イプシロングリーディー）


イプシロングリーディー（ε-greedy）
は、学習が偏らないように使う
多腕バンディットにも使われている

そして、方策勾配法、Q学習のメリットを両方使えるのが
Actor-Critic　アクタークリティック（アクターが方策、クリティックが価値）

方策勾配法（actor）＋Q学習的な価値評価（Critic）


まとめ

方策勾配法
・行動選択の基準は、学んだ、確率、ルール、に従って動く
・探索の仕方は、確率分布の中に探索が自然に含まれる

Q学習
・行動選択の基準は、価値が最大の行動を優先的に選ぶ
・探索の仕方は、イプシロングリーディーなどで明示的に探索





















