# 🧠 表現学習（Representation Learning／レプレゼンテーション・ラーニング）

## ■ 定義
**表現学習（Representation Learning）**とは、  
データの**本質的な特徴（特徴量）を自動で見つけ出し、コンピュータが理解しやすい形に変換する学習**のこと。

つまり、人間が「特徴量エンジニアリング」せんでも、  
AIが自分で“データの見方”を覚える仕組みやねん。

---

## ■ 目的と効果

| 目的 | 内容 |
|------|------|
| **次元削減** | 膨大なデータを少ない次元に圧縮して扱いやすくする |
| **特徴抽出** | モデルが自ら意味のある特徴を発見する |
| **汎化性能の向上** | 未知のデータに強くなる（過学習を防ぐ） |
| **転移学習の基盤** | 学んだ表現を別タスクに再利用できる（例：BERTなど） |

---

## ■ 主な手法

### ① 教師なし表現学習（Unsupervised Representation Learning）
- 正解ラベルなしでデータの構造を学ぶ。  
- 例：**クラスタリング**, **PCA（主成分分析）**, **オートエンコーダ（Autoencoder）**

---

### ② 自己符号化器（Autoencoder：オートエンコーダ）
- 入力データをいったん**圧縮（エンコード）**し、そこから**再構成（デコード）**する構造。  
- 圧縮部分（潜在ベクトル）が「良い表現」になる。

📘 **代表例**
- Autoencoder  
- Denoising Autoencoder（ノイズ除去型）  
- Variational Autoencoder（VAE：生成モデルにも応用）

---

### ③ 自己教師あり学習（Self-Supervised Learning）
- データの一部を「擬似ラベル」にして学ぶ手法。  
- 例：「欠けた単語を予測」「画像の一部を復元」など。

📘 **代表例**
- **BERT**（テキストのマスク予測）  
- **SimCLR**, **MoCo**, **BYOL**（画像のペアで特徴を学ぶ）  
- **wav2vec**, **HuBERT**（音声表現学習）

> ラベルなしでもラベルあり並みに賢くなる、近年の主流。

---

### ④ 距離学習（Metric Learning）
- データ間の「似てる」「似てない」を**距離で学ぶ**。  
- 類似データを近く、異なるデータを遠く配置するよう学習。

📘 **代表例**
- Siamese Network（類似度学習）  
- FaceNet（顔認識）  
- コントラスト損失、トリプレット損失

---

### ⑤ 深層表現学習（Deep Representation Learning）
- 深層ニューラルネットを使って多層的に特徴を抽出。  
- 下層ほど「エッジ・形」、上層ほど「意味・概念」を学ぶ。

📘 **代表モデル**

| 分野 | モデル例 |
|------|-----------|
| 画像 | CNN, ResNet, SimCLR, DINO |
| 音声 | wav2vec, HuBERT |
| テキスト | word2vec, BERT, GPT |
| マルチモーダル | CLIP, DALL·E |

---

## ■ イメージで理解
人間が「猫」を見るときも、
- 「毛がふわふわ」  
- 「目がまるい」  
- 「鳴き声が高い」  

みたいに特徴を抽出してる。  
表現学習は**それをAIが自動でやる**ようにしたもの。

---

## ■ 数学的なイメージ（テキスト形式）
入力データ X → 特徴表現 h = f(X; θ) → 出力 Y

この **f(X; θ)** の部分が「データの表現（representation）」を学ぶところ。  
モデルが“どんな見方をしてるか”を学習してるんや。

---

## ■ 応用分野

| 分野 | 活用例 |
|------|--------|
| 画像認識 | 顔認識、物体検出、医用画像解析 |
| 音声処理 | 音声認識、話者識別、音楽解析 |
| 自然言語処理 | 翻訳、要約、質問応答、生成AI |
| 推薦システム | ユーザーとアイテムのベクトル表現 |
| ロボティクス | 環境認識と行動選択 |

---

## ■ まとめ

| 項目 | 内容 |
|------|------|
| **意味** | データを理解しやすい形に変換する学習 |
| **目的** | 特徴抽出・次元削減・汎化性能UP |
| **主な手法** | Autoencoder／Self-Supervised／Metric Learning |
| **メリット** | 特徴設計不要・再利用可能 |
| **代表モデル** | CNN・BERT・GPT・SimCLR・VAE |

---

## 💬 一言で言うと
> 表現学習とは、AIが「データを見る目」を養う仕組み。  
> 人間で言えば、「観察眼を鍛える訓練」みたいなもんやな。

---

AIが**「何をどう見て理解するか」**を自分で学ぶ。  
つまり、「見る力」「気づく力」を育てる学習やねん。
