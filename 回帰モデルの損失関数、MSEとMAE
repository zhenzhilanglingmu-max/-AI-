＃回帰モデルの代表的な損失関数
＃損失関数
＃平均二乗誤差(MSE）Mean squcred Error
＃平均絶対誤差（MAE）Mean Absolute Error
＃精度ガチ追及　ＭＳＥ
＃安定性重視　ＭＡＥ
＃両方いいとこどり　Ｈｅｂｅｒ

損失関数は回帰モデルまたは、分類モデルが効率よく学習するために、ズレを修正する
学習とゴールを決める道しるべ

方向　どっちにパラメータを動かせばいいか（勾配の符号）　　パラメータは、現在地（重み、バイアス）
ゴール　どの状態を「最適」って呼ぶか（損失が最小になる点）

損失関数がちゃんとしてないと、モデルは間違った方向に進んだり、ゴールがずれたりする
逆に言えばタスクに合った損失関数を選べば、効率的に正解に近けること

平均二乗誤差（MSE)

・誤差を二乗して平均するから、ちょっと大きなズレでも、めっちゃ誤差を膨らませて目立たせる計算

・誤差が見えやすくなって「ここを直せば、精度が上がる」ってなって、直すポイントをはっきり示してくれる

・大きな誤差をガンガンつぶしていくから学習スピードは速いけど、外れ値、にも敏感でバランスを崩しやすい

イメージでいえば、集中投資型（高リスク、高リターン）な投資
大きく当たればいいけど、大きく外れれば損する


平均絶対誤差（MAS）

・誤差の絶対値を平均するから、大きなズレも小さなズレも、同じ強さ（±１）プラスマイナス「１」で修正
絶対値（誤差のプラスマイナスを消す）ー８は８に　＋４は４にすること

・「これズレてるけど、この辺に寄せよか」って感じで、中央値に寄せて、安定化させる

・外れ値に振り回されないロバスト性（安定性）があるけど、細かい詰め（精度の微調整）はMSEより遅い

イメージでいえば、インデックスファンド型（安定志向）

まとめると、

・安定させたいとき
ＭＡＥ　（少しのズレは考慮して、全体を落ち着かせる）

・時間がかかても、厳密にしたいとき
ＭＳＥ（外れ値を膨らませて、誤差をみつけて精度ＵＰ！）

・両方の長所を取りたいなら
Ｈｕｂｅｒ損失
（小さいズレは、ＭＳＥ、大きなズレはＭＡＥ）

チャットGTPから　それぞれの式
## 平均二乗誤差（MSE: Mean Squared Error）

$$
MSE = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2
$$

- $y_i$: 実際の値（正解値）  
- $\hat{y}_i$: 予測値  
- $n$: サンプル数  

---

## 平均絶対誤差（MAE: Mean Absolute Error）

$$
MAE = \frac{1}{n} \sum_{i=1}^n \left| y_i - \hat{y}_i \right|
$$

- $y_i$: 実際の値（正解値）  
- $\hat{y}_i$: 予測値  
- $n$: サンプル数  

---

## Huber損失（Huber Loss）

$$
L_{\delta}(r) =
\begin{cases}
\frac{1}{2} r^2 & \text{if } |r| \leq \delta \\\\
\delta \left( |r| - \frac{1}{2} \delta \right) & \text{if } |r| > \delta
\end{cases}
$$

ここで、$r = y_i - \hat{y}_i$

- $\delta$: しきい値（この値以下はMSE、それ以上はMAEとして扱う）  
- 小さい誤差 → MSEモード（素早く詰める）  
- 大きい誤差 → MAEモード（外れ値の影響を抑える）  














