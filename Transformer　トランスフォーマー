＃Transformer（トランスフォーマー
＃エンコーダー
＃デコーダー
＃attention機構（アテンション）

エンコーダーは、理解する人　デコーダーは、説明する人
アテンションattention機構は注意を向ける

・エンコーダー（理解する人）
・役割：入力（文章、画像など）を圧縮して理解
・アテンション：双方向自己注意（self-Attention）　前後の文脈を同時に見て、関係性を把握
　　　　　　　　　　　　使われる代表モデルＢＥＲＴ（読解特化）

　　　　　　　　　　　例えると、本を読んでノートにまとめる優等生

・デコーダー（説明する人）

・役割：頭の中の情報から、順に言葉を生成
・アテンション、自己注意（Causal Masked self Attention）　未来は見ないで左から右へ一語ずつ生成
・クロス注意（Cross-Attention）　エンコーダーの情報を参照してしゃべる
　　　　　　　　　　　　　　使われてる代表モデルはＧＰＴ（生成特化）

　　　　　　　　　　　　　　　　　例えると、ノートやカンペを見ながら（わかりやすく説明する人）






