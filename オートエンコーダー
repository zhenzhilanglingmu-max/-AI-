# オートエンコーダー (Autoencoder)

## 基本構造
1. **入力 (Input)**
   - 例: 画像 28×28 → 784次元ベクトル

2. **エンコーダー (Encoder)**
   - 入力データをだんだん圧縮
   - 情報を凝縮して不要なノイズを削除

3. **潜在表現 / ボトルネック (Latent Space / Bottleneck)**
   - データを最も小さくまとめた部分
   - 大事な特徴だけが残る

4. **デコーダー (Decoder)**
   - 潜在表現から再び元の大きさに復元
   - 出力が入力に近いほど圧縮が上手くいっている

---

## なんで元の大きさに戻すの？
- 圧縮の精度を確認するため  
  → 小さい表現から復元しても元に近ければOK  
- 自己教師あり学習ができる  
  → 入力そのものを正解データとして使える  

---

## メリット
- **コンパクト化**: 大量のデータを扱いやすくする  
- **復元可能**: 必要なときに元サイズへ再構成できる  
- **柔軟性**: 小さい特徴ベクトルのまま使うことも、復元して使うこともできる  

---

## イメージ例
- **ZIP圧縮と解凍**  
  → データを小さく保存して、必要に応じて元の大きさに戻す  

- **要点メモ**  
  → 大事な部分だけ残して、後で思い出せる  

---

## まとめ
オートエンコーダーは  
👉 **「情報をコンパクトにする」＋「元に戻せる」**  
という、シンプルで融通の効く仕組み。  

---

## さだヤンの考え
オートエンコーダーは、  
**「コンパクトに小さくすることで大きな量も扱いやすくなる」**  
さらに **「必要になったら元に戻せるから融通が効く」** 仕組みやと解釈した。
