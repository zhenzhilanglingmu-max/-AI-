# RNN (Recurrent Neural Network) の代表的なモデルまとめ

## 1. ジョルダンネットワーク (Jordan Network)
- **構造**：出力をフィードバックして次の時刻の入力に渡す  
- **役割**：過去の「答えの履歴」を次の判断に活かす  
- **イメージ**：テストの答えを覚えて次の問題に役立てる  
- **用途**：単純な時系列予測、シナリオ生成の初歩  

---

## 2. エルマンネットワーク (Elman Network)
- **構造**：隠れ層の状態をフィードバックする  
- **役割**：過去の「思考（特徴抽出の結果）」を保持して次に使う  
- **イメージ**：「頭の中の考え」を一時的に記憶して次の判断に反映  
- **用途**：音声認識、系列分類、文脈のある予測  

---

## 3. LSTM (Long Short-Term Memory)
- **構造**：セル状態とゲート（入力・忘却・出力）を持つ  
- **役割**：必要な情報は長期的に保持し、不要な情報は忘れる  
- **イメージ**：頭の中に「重要メモ帳」を持っている  
- **用途**：長文の翻訳、文章生成、株価やセンサーデータの予測  

---

## 4. Transformer（参考）
- **構造**：リカレント構造は持たず、Attention 機構で系列全体を同時に処理  
- **役割**：系列内の依存関係を一気に把握  
- **イメージ**：全体を見渡して重要な部分に注目する先生  
- **用途**：翻訳、ChatGPT を含む大規模言語モデル、画像・マルチモーダル処理  

---

## ✅ まとめ（構造あり/なし）
| モデル | 構造の種類 | RNNか？ | 特徴 |
|--------|------------|---------|------|
| ジョルダンネットワーク | 出力をフィードバック | ✅ | 過去の答えを活かす |
| エルマンネットワーク | 隠れ層をフィードバック | ✅ | 過去の思考を活かす |
| LSTM | セル状態＋ゲート | ✅ | 長期依存を扱える |
| Transformer | Attention機構 | ❌ | 全体を一度に見る |

---
